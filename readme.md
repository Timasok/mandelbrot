# Отчёт по работе SIMD

## Цель работы

Освоение методов оптимизации с помощью процессорных SIMD инструкций.

## Введение
"SIMD" (Single Instruction, Multiple Data - поток одной команды, множественный поток данных) - одна из моделей параллельных вычислений. В архитектурах, поддерживающих её, можно проводить операции с векторными типами, за время одной команды. Для этого на машинном уровне существуют расширенные "xmm" регистры. Функции, использующие эту технологию, называются SIMD-инструкциями и часто применяются в оптимизации алгоритмов.

<!--
`SIMD` (Single Instruction, Multiple Data - одиночный поток команд, множественный поток данных) - принцип вычислений, позволяющий обеспечить параллелизм выполнения команд. Архитектуры современных процессоров позволяют выполнять несколько инструкций одновременно, параллельно при помощи специальных расширенных `xmm` регистров. Эти возможности и используются в ходе оптимизации вычислений с помощью SIMD инструкций. В работе используются наборы команд `SSE4` и `AVX2`. Стоит отметить, что эти технологии доступны не на всех процессорах.

Конвейерная обработка команд процессором имеет несколько недостатков, один из них - риск загрузки и использования. Он возникает из-за зависимости следующей команды от результата предыдущей, поэтому процессор условно приостанавливает конвейер, пока не будет выполнена предыдущая инструкция. Чтобы сократить количество таких зависимостей применяется векторная обработка данных (отсюда и название - одна операция, множественный поток данных) с помощью специальных наборов команд (в этой работе представлены `SSE4` и `AVX2`).
-->
## Ход работы

### Часть 1. Множество Мандельброта

#### Теоретическая справка

Мно́жество Мандельбро́та — множество точек на комплексной плоскости, для которых рекуррентное соотношение ``Z(n+1)^2 = Z(n)^2+Z0`` при ``Z0 = 0`` задаёт ограниченную последовательность.

В целом этот фрактал можно обсчитать по следующему алгоритму:

``Z(n+1)^2 = Z(n)^2+Z0``, где ``Z0`` - координата начальной точки на комплексной или декартовой плоскости. 
Координаты ```Z(n+1)``` вычисляются по правилу:

```X(n+1) = X(n)^2 - Y(n)^2 + X0```

```Y(n+1) = 2*X(n)*Y(n) + Y0```

Вычисления продолжаются до тех пор, пока расстояние от ```Z(n)``` до начала координат ```(0, 0)``` не превысит ```R_max = 10``` или пока ```n (number_of_iterations)``` не превысит ```N_max = 256```. 

Подробнее про этот алгоритм можно прочитать тут: 
https://webdesign.ru.net/article/pravila-oformleniya-fayla-readmemd-na-github.html

Вот пример изображения, выдаваемого нашей программой:
![Mandelbrot](img/Mandelbrot_set.png)

#### Простейший алгоритм

Объявление констант:

```C++
    const int N_max = 256;
    const float EPS = 0.001
    const float R_max = 10.0;
    const float R_max2 = R_max*R_max;

    const int w_width   = 1000;
    const int w_height  = 1000;

    const float x_max =  2.0;
    const float x_min = -2.0;
    const float y_max =  2.0;
    const float y_min = -2.0;

    float dx = (x_max - x_min)/w_width;
    float dy = (y_max - y_min)/w_height;
```

```C++
    int yi = 0;
    for (; yi < w_height; yi++)
    {
        float Y0 = y_min + (Y_shift+yi)*dy*scale;

        int xi = 0;
        for(; xi < w_width; xi++)
        {
            float X0 = x_min + (X_shift + xi)*dx*scale;

            float X  = X0;
            float Y  = Y0; 

            float R2 = X*X + Y*Y;

            int n = 0;
            while (n < N_max && R2 - R_max2 < EPS)
            {
                float X2  = X*X;
                float Y2  = Y*Y;
                float XY  = X*Y + X*Y; 

                X = X2 - Y2 + X0;
                Y = XY + Y0;

                R2 = X2 + Y2;

                n++;
            }
            static volatile n_res = n; 
        }
    }
```
Ключевое слово ```volatile``` возле переменной придаёт ей статус неоптимизируемой. Таким образом все вычисления, в которых она участвует, компилятор оставляет без оптимизации. 

Мы не позволяем компилятору отбросить неиспользуемые значения. После каждого вычисления ```n```, создаём ```volatile``` переменную ```n_res```. А затем присваиваем ей значение ```n```. И даже если в дальнейшем ```n```, т.е. цвет каждого пикселя из множества Мандельброта не будет использоваться алгоритм сохранит свою целостность.

#### Оптимизированный алгоритм

Оптимизируем данный код, воспользовавшись набором команд ```SSE4``` из библиотеки ```<xmmintrin.h>```. Стоит заметить, что не каждый процессор поддерживает данный набор команд.

```C++
    int N_BITES = 4;
    __m128 R2_max = _mm_set1_ps(R_max2);
    __m128 Mask   = _mm_set1_ps(0x0001);

    for(int cnt = 0; cnt < COUNTS; cnt++)
    {
        int yi = 0;
        for (; yi < Mandb_Initial.w_height; yi++)
        {
            __m128 Y_SHIFT = _mm_set1_ps(y_min + Y_shift*dy*scale);
            __m128 DY = _mm_set1_ps(dy*scale);
            __m128 Y0 = _mm_set1_ps(yi);
            Y0 = _mm_mul_ps(Y0, DY);
            Y0 = _mm_add_ps(Y0, Y_SHIFT);

            int xi = 0;
            for(; xi < w_width; xi+=N_BITES)
            {
                __m128 X_SHIFT = _mm_set1_ps(x_min + X_shift*dx*scale);
                __m128 DX = _mm_set1_ps(dx*scale);
                __m128 X0 = _mm_set_ps(xi, xi+1, xi+2, xi+3);

                X0 = _mm_mul_ps(X0, DX);
                X0 = _mm_add_ps(X0, X_SHIFT);
                
                __m128 X = X0;
                __m128 Y = Y0; 

                __m128 n   = _mm_setzero_ps();
                __m128 cmp = _mm_set1_ps(1);
                
                for(int i = 0; i < N_max; i++)
                {
                    __m128 X2 = _mm_mul_ps(X, X);
                    __m128 Y2 = _mm_mul_ps(Y, Y);
                    __m128 R2 = _mm_add_ps(X2, Y2);

                    cmp = _mm_cmplt_ps (R2, R2_max);
                                                                                    
                    int mask  =_mm_movemask_ps (cmp);                                

                    if (!mask)
                        break;

                    __m128 XY = _mm_mul_ps(X, Y); 
                    XY = _mm_add_ps (XY, XY);

                    X = _mm_sub_ps (X2, Y2);
                    X = _mm_add_ps (X, X0);
                    Y = _mm_add_ps (XY, Y0);
                                            
                    cmp = _mm_and_ps(cmp, Mask);

                    n = _mm_add_ps(n, cmp);
                
                } ;
                
                volatile __m128 n_res = n;      
          }
      }
  }
     
```
Рассмотрим подробнее тип ```__m128```, преимущественно используемый нами в этой оптимизации. Он представляет из себя 4 float-а по 32-бита, упакованных в массив. Данные ```_mm_```функции позволяют выполнять операции для несколькими значениями одновременно. В данном случае в цикле вычисляются 4 значения ```n``` для 4-х значений $(x_0, y_0)$. Так как результаты вычислений полностью независимы друг от друга, то использование конвейера оправдано.

#### Погрешности измерений

Напрямую измерим *iteration time* с помощью ```sf::Clock```. А на основе этого вычислим *FPS* по формуле: *FPS* = 1/*iteration time*. 

Чтобы избавиться от временой задержки, возникающей при вызове функции ```GetFPS()```, сделаем её inline-функцией.

В грубом приближении справедлива эта формула:

```iteration time = number_of_pixels*(calculation_time + drawing_time)```

Так как оптимизируемой величиной в данной работе является скорость **вычисления** множества Мандельброта, то отображение, скорость которого невозможно оптимизировать, было бы целесообразно отключить. Чтобы сравнить скорость отрисовки со скоростью вычислений, запустим программу в следующих режимах:

1. Без отрисовки.
2. С отрисовкой.

#### Измерения
  
В таблице снизу приведены значения *FPS* при разных настройках запуска. Также для каждого посчитан коэффицент ускорения относительно первой ячейки этой строки, т.е запуска без флагов. 

|   **Режимы запуска**  | **Без флагов**  |     **-O2**     |     **-O3**     |     **-Ofast**    |
| :---------------: | :----------:| :---------: | :---------: | :----------:  |
|    1 + no_sse     |  **6.15** (1x) | 11.1 (1.8x) | 11.2 (1.8x) |  11.6  (1.9x) |
|    2 + no_sse     |   1.43 (1x) | 1.81 (1.3x) | 1.77 (1.2x) |  1.65  (1.2x) |
|    1 + sse        |   8.62 (1x) | 39.6 (4,6x) | 40.3 (4.7x) | **42.6** (4.9x) |

Сравнивая первые два ряда таблицы, мы можем заключить, что:
+ 2-й режим плохо ускоряется даже компиляторными флагами оптимизации. 
+ Время рисования примерно в **5** раз больше времени расчётов.

*Как и говорилось ранее запуск программы во 2-м режиме бессмысленен. Также потому, что ускорение во 2-м режиме с помощью SSE не будет заметно.*

Максимальные коэффициенты ускорения с помощью -O флагов в каждой строке следующие:
+ K_o = **1.9**
+ K_o = **1.3**
+ K_o = **4.9**

В таблице выделена наибольшая скорость работы алгоритма и наименьшая скорость работы алгоритма. Коэффициент ускорения после комбинирования SIMD и -O оптимизаций получился следующим:
+ K_sse+o = 42.6/6.15 = **6.9**

### Часть 2. Alpha Blending

#### Теоретическая справка

Альфа-смешение - это процесс комбинирования одного изображения с фоном для создания видимости частичной или полной прозрачности.

#### Простейший алгоритм

Суть алгоритма такова: В области, где изображения не накладываются, цвет итогового изображения равен цвету фона. В остальной области цвет каждого пикселя задаём по следующему правилу:

~~~C++
result_pixel.color = (front_pixel.alpha*front_pixel.color + (255 - front_pixel.alpha)*back_pixel.color)/255;
~~~

В качестве фона мы использовали теннисный стол, а в качестве накладывемого изображения - котика:

![Table](img/Table.bmp)
![Cat](img/AskhatCat.bmp)

Результат получался следующим:

![result](img/result_example.bmp)

#### Оптимизированный алгоритм

```
   const __m128i _0 = _mm_set1_epi8(0);
   const __m128i _255  = _mm_set1_epi16(255);

    int step = N_BYTES-1;
    if (front->width-delta_x<N_BYTES)
    {
        step = front->width-delta_x - 1;
    }

    size_t front_counter = (delta_y*front->width + delta_x);

    __m128i front_pixel = _mm_loadu_si128((__m128i const *)(&front->pixels[front_counter]));
    __m128i back_pixel  = _mm_loadu_si128((__m128i const *)(&back->pixels[back_counter]));

    __m128i FRONT_PIXEL = (__m128i) _mm_movehl_ps((__m128) _0, (__m128) front_pixel);
    __m128i BACK_PIXEL = (__m128i) _mm_movehl_ps((__m128) _0, (__m128) back_pixel);

    front_pixel = _mm_cvtepu8_epi16 (front_pixel);
    back_pixel = _mm_cvtepu8_epi16 (back_pixel);

    FRONT_PIXEL = _mm_cvtepu8_epi16 (FRONT_PIXEL);
    BACK_PIXEL = _mm_cvtepu8_epi16 (BACK_PIXEL);

const   __m128i alpha_mask = _mm_setr_epi8(6, zero_val, 6, zero_val, 6, zero_val, 6, zero_val, 14, zero_val, 14, zero_val, 14, zero_val,
    14, zero_val);

    __m128i front_alpha = _mm_shuffle_epi8(front_pixel, alpha_mask);                  // front.a(0,1)
    __m128i FRONT_ALPHA = _mm_shuffle_epi8(FRONT_PIXEL, alpha_mask);                  // front.a(2,3)

    front_pixel = _mm_mullo_epi16(front_pixel, front_alpha);
    FRONT_PIXEL = _mm_mullo_epi16(FRONT_PIXEL, FRONT_ALPHA);
    back_pixel = _mm_mullo_epi16(back_pixel, _mm_sub_epi16 (_255, front_alpha));
    BACK_PIXEL = _mm_mullo_epi16(BACK_PIXEL, _mm_sub_epi16 (_255, FRONT_ALPHA));

    __m128i sum_low = _mm_add_epi16(front_pixel, back_pixel);
    __m128i sum_high = _mm_add_epi16(FRONT_PIXEL, BACK_PIXEL);

const   __m128i sum_mask = _mm_setr_epi8(1, 3, 5, 7, 9, 11, 13, 15, zero_val, zero_val, zero_val, zero_val, zero_val, 
                                            zero_val, zero_val, zero_val);

    sum_low = _mm_shuffle_epi8(sum_low, sum_mask);
    sum_high = _mm_shuffle_epi8(sum_high, sum_mask);
    volatile __m128i color = (__m128i)_mm_movelh_ps((__m128)sum_low, (__m128)sum_high); 

    _mm_storeu_si128 ((__m128i*) &(result->pixels[back_counter]), color) ;
```
*Также ещё одним неочевидным ускорением алгоритма могло быть выравнивание размера накладываемого изображение под размер фона. Тогда можго было бы убрать ```if```, связанный с проверкой на наложение картинок.*

#### Погрешности измерений

Систематическая погрешность в этом эксперименте схожа с предыдущей из-за тех же приёмов измерения времени. Применяется ```sf::Clock```.

Но вот замедление алгоритма из-за отрисовки тут отсутствует, т.к. процессы формируем изображения и записи его в файл происходят последовательности. И поэтому медленное сохранение в файл не увеличивает погрешность измерения основного алгоритма.

#### Измерения

| O_flag | SSE/NO SSE  |  FPS   |  Coeff |
| :----: |  :--------: | :----: | :----: |
|  -O0   |    NO SSE   | **2200** |  1     |
|  -O2   |    NO SSE   | 4800  |  2.18  |
|  -O3   |    NO SSE   | 5400  |  2.45  |
| -Ofast |    NO SSE   | 5900  |  2.68  |
|  -O0   |     SSE     | 4400  |  2  |
|  -O2   |     SSE     | 14500 |  6.59  |
|  -O3   |     SSE     | **18300**  |  **8.32**   |
| -Ofast |     SSE     | 13500 |  6.14  |

На основе данной таблицы можно сделать следующие выводы:
+ -Ofast не всегда является самым быстрым флагом оптимизации
+ Ускорение SSE без флагов сопоставимо с ускорением c флагами без SSE (2-3 раза)
+ Все значения FPS округлены до сотых, так что тут разумнее было бы измерять время напрямую, т.е. *iteration_time*

Комбинируя две оптимизации нам удалось добиться ускорения в **8,5** раз!

## Результаты

Основная задача проекта была выполнена. Мы научились снижать систематическую погрешность измерения времени работы алгоритма, и оптимизировать его с помощью SIMD-инструкций. Нашему процессору доступны интринсиксы типа ```AVX2``` и ```AVX-512```, не нашедшие отражения в данной работе, из-за чего не была достигнута максимально возможное быстродействие. Однако результат использования ```SSE4``` тоже велик: в 1-м и 2-м экспериментах удалось ускорить алгоритм в 7-8 раз. Отсюда следует, что параллелизм значительно повышает производительность. 

## Источники и литература

1. Устройство технологии SIMD:
  - http://ftp.cvut.cz/kernel/people/geoff/cell/ps3-linux-docs/CellProgrammingTutorial/BasicsOfSIMDProgramming.html

2. Классы sf::Clock и графика взяты из библиотеки SFML:
  - https://www.sfml-dev.org/

3. Источник SIMD-инструкций для процессоров intel:
  - https://www.laruence.com/sse

----------------

<!-- Т.к. одного вычисления одного цвета это ```calculation_time```, а измерять мы можем без замедления самих вычислений только ```iteration time```. Поэтому для снижения погрешности можно увеличить вес вычислений в ```k = 1000``` раз. Тогда 
```iteration time/k = number_of_pixels*(calculation_time*k + drawing_time) ≈ number_of_pixels*calculation_time``` -->
